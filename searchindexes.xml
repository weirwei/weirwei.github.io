<?xml version="1.0" encoding="utf-8" standalone="yes"?><search><entry><title>MySQL where 范围查询和 order by 关键字无法同时命中索引</title><url>/post/index_in_orderby/</url><categories><category>实战问题</category></categories><tags><tag>MySQL</tag><tag>索引</tag></tags><content type="html"><![CDATA[   开发中，使用 in 和 order by 的时候，发现无法同时命中索引。
使用 IN 运算符来过滤行时，MySQL 会先使用索引来定位表中的行，并将这些行的所有数据读入内存中。随后，MySQL 会根据查询语句中的 ORDER BY 子句对这些数据进行排序。
简单场景构造 CREATE TABLE `c` ( `id` bigint unsigned NOT NULL AUTO_INCREMENT, `a` int NOT NULL DEFAULT &#39;0&#39;, `b` int NOT NULL DEFAULT &#39;0&#39;, `c` int NOT NULL DEFAULT &#39;0&#39;, PRIMARY KEY (`id`), KEY `abc` (`a`,`b`,`c`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci -- data insert into c(a, b, c) values (1, 1, 1), (1, 1, 2), (1, 1, 3), (1, 2, 1), (1, 2, 2), (1, 2, 3), (1, 2, 3), (2, 2, 2), (3, 3, 3); Explain SELECT 非范围查询 explain select * from c where a = 1 and b = 1 order by c; /* +----+-------------+-------+------------+------+---------------+------+---------+-------------+------+----------+-------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+-------+------------+------+---------------+------+---------+-------------+------+----------+-------------+ | 1 | SIMPLE | c | NULL | ref | abc | abc | 8 | const,const | 3 | 100.00 | Using index | +----+-------------+-------+------------+------+---------------+------+---------+-------------+------+----------+-------------+ */ 能够完美命中索引。
范围查询 explain select * from c where a = 1 and b &gt; 1 order by c; /* +----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+------------------------------------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+------------------------------------------+ | 1 | SIMPLE | c | NULL | range | abc | abc | 8 | NULL | 4 | 100.00 | Using where; Using index; Using filesort | +----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+------------------------------------------+ */ 范围查询用到了filesort，表示 order by没有命中索引，abc 索引的作用相当于 ab。
索引分析 索引结构
a b c 1 1 1 2 3 2 1 2 3 3 2 2 2 3 3 3 select * from c where a = 1 and b = 1 order by c; 在非范围查询的时候，可以发现，经过where语句，c的范围是 1、2、3，b已确定，c 有序，order by 可以命中索引。
select * from c where a = 1 and b &gt; 1 order by c; 在范围查询的时候，经过where语句，c的范围是 1、2、3、1、2、3、3，b无法确定（可能为1或2），c 为无序，order by 无法命中索引。
  ]]></content></entry><entry><title>Gorm 的黑魔法</title><url>/post/gorm_black_magic/</url><categories><category>实战问题</category></categories><tags><tag>golang</tag><tag>gorm</tag></tags><content type="html"><![CDATA[   小伙看到同事写的Gorm黑魔法，逐渐不淡定了。
开发过程中，看到同事的代码写了这么一段：
db = db.Session(&amp;amp;gorm.Session{Context: db.Statement.Context}).FirstOrCreate(&amp;amp;entity) if db.Error !=nil{ return components.ErrorDbInsert.WrapPrintf(db.Error, &amp;#34;Insert error, entity:%s&amp;#34;, utils.ToJson(entity)) } if db.RowsAffected == 0 { return components.ErrorAlreadyExist } FirstOrCreate 我不禁感到疑惑，gorm 的 RowsAffected 在进行查询，如果查到数据，也是有值的，为什么在这里可以用 RowsAffected == 0 来判断数据已存在？
抱着这个疑问，我点开了 FirstOrCreate 的代码：
func (db *DB) FirstOrCreate(dest interface{}, conds ...interface{}) (tx *DB) { queryTx := db.Limit(1).Order(clause.OrderByColumn{ Column: clause.Column{Table: clause.CurrentTable, Name: clause.PrimaryKey}, }) if tx = queryTx.Find(dest, conds...); queryTx.RowsAffected == 0 { ... return tx.Create(dest) } else if len(db.Statement.assigns) &amp;gt; 0 { ... return tx.Model(dest).Updates(assigns) } return db } 我们可以很容易地发现，在 Find 查到数据且 assigns 没有值的情况下，return 的是 db，而其他情况下 return 的是 tx。直觉告诉我，原因大概率在这个上面。
getInstance() Limit、Order、Find等许多函数都调用了同一 …  ]]></content></entry><entry><title>MySQL 索引排序</title><url>/post/mysql_index_sort/</url><categories><category>存储</category></categories><tags><tag>MySQL</tag><tag>索引</tag></tags><content type="html"> 开发过程中发现SQL一直filesort，所以研究一下到低怎么才能使用索引进行排序。
表结构和数据 CREATE TABLE `t1` ( `id` int(11) NOT NULL AUTO_INCREMENT, `a` int(11) DEFAULT NULL, `b` int(11) DEFAULT NULL, `c` int(11) DEFAULT NULL, PRIMARY KEY (`id`), KEY `idx_a_b_c` (`a`,`b`,`c`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; id a b c 1 1 5 3 2 5 3 3 3 4 5 9 4 2 6 1 5 4 3 2 6 5 5 5 7 1 2 1 8 5 5 8 9 5 3 9 10 5 5 1 11 5 7 7 SQL explain select * from t where a = 5 order by c desc; -- type:ref -- key:idx_a_b_c -- ref:const -- Extra:Using where; Using index; Using filesort explain select * from t where a = 5 order by b desc; -- type:ref -- key:idx_a_b_c -- ref:const -- Extra:Using where; Using index explain select * from t where a = 5 and c = 5 order by b desc; -- type:ref -- key:idx_a_b_c -- ref:const -- Extra:Using where; Using index explain select * from t where a = 5 and b = 5 order by c desc; -- type:ref -- key:idx_a_b_c -- ref:const,const -- Extra:Using where; Using index explain select * from t where a = 5 and b &amp;gt;= 5 order by c desc; -- type:range -- key:idx_a_b_c -- ref:NULL -- Extra:Using where; Using index; Using filesort 索引分析 通过观察联合索引的数据结构，很明显就能发现索引都是有序的，使用索引进行排序就是利用了这个特性。
我们来观察 a = 5 的这一段索引，很容易就能发现，在 a 确定的情况下，b 是有序的，但c 是无序的。a 和 b 命中索引，a 和 c 不命中索引
在 a,b 都确定的情况下，c 是有序的。a,b,c 命中索引
这就是老生常谈的 最佳左前缀原则 也叫 最左前缀匹配原则
因此，要让排序项使用索引进行排序
第一个条件就是：where条件+排序项符合最佳左前缀原则
第二个条件：不能使用条件查询
这个也可以通过观察联合索引得出结论
a = 5 AND b &amp;gt;= 5 显然是无法保证 c 是有序的
结论 要让order by 使用索引排序，需要至少满足以下条件：
where条件+排序项符合最佳左前缀原则 不能使用条件查询</content></entry><entry><title>go 的切片扩容</title><url>/post/slice_expand/</url><categories><category>语言学习</category></categories><tags><tag>golang</tag></tags><content type="html"><![CDATA[   在uber 的go语言编码规范中有这么一条，2.48s 和0.21s 的差距还是很惊人了，我很好奇，why？
切片在append的时候可能会自动扩容，看一下相关源码。
slice type slice struct { array unsafe.Pointer len int cap int } func makeslice(et *_type, len, cap int) unsafe.Pointer { // 1. 计算需要申请的容量，并判断是否内存溢出 mem, overflow := math.MulUintptr(et.size, uintptr(cap)) // 2. 内存溢出原因 if overflow || mem &gt; maxAlloc || len &lt; 0 || len &gt; cap { // 计算slice所需内存通过MulUintptr来实现的 mem, overflow := math.MulUintptr(et.size, uintptr(len)) if overflow || mem &gt; maxAlloc || len &lt; 0 { panicmakeslicelen() } panicmakeslicecap() } // 3. 进行内存分配 return mallocgc(mem, et, true) } func growslice(et *_type, old slice, cap int) slice { ... newcap := old.cap doublecap := newcap + newcap if cap &gt; doublecap { newcap = cap } else { // 当原切片长度小于1024时，新切片的容量会直接翻倍。而当原切片的容量大于等于1024时，会反复地增加25%，直到新容量超过所需要的容量 if old.cap &lt; 1024 { newcap = doublecap } else { for 0 &lt; newcap &amp;&amp; newcap &lt; cap { newcap += newcap / 4 } if newcap &lt;= 0 { newcap = cap } } } var overflow bool var lenmem, newlenmem, capmem uintptr switch { case et.size == 1: lenmem = uintptr(old.len) newlenmem = uintptr(cap) capmem = roundupsize(uintptr(newcap)) overflow = uintptr(newcap) &gt; maxAlloc newcap = int(capmem) case et.size == sys.PtrSize: lenmem = uintptr(old.len) * sys.PtrSize newlenmem = uintptr(cap) * sys.PtrSize capmem = roundupsize(uintptr(newcap) * sys.PtrSize) overflow = uintptr(newcap) &gt; maxAlloc/sys.PtrSize newcap = int(capmem / sys.PtrSize) case isPowerOfTwo(et.size): var shift uintptr if sys.PtrSize == 8 { // Mask shift for better code generation. shift = uintptr(sys.Ctz64(uint64(et.size))) &amp; 63 } else { shift = uintptr(sys.Ctz32(uint32(et.size))) &amp; 31 } lenmem = uintptr(old.len) &lt;&lt; shift newlenmem = uintptr(cap) &lt;&lt; shift capmem = roundupsize(uintptr(newcap) &lt;&lt; shift) overflow = uintptr(newcap) &gt; (maxAlloc &gt;&gt; shift) newcap = int(capmem &gt;&gt; shift) default: lenmem = uintptr(old.len) * et.size newlenmem = uintptr(cap) * et.size capmem, overflow = math.MulUintptr(et.size, uintptr(newcap)) capmem = roundupsize(capmem) newcap = int(capmem / et.size) } ... } package runtime // 内存对齐的过程，为了避免造成过多的内存碎片 func roundupsize(size uintptr) uintptr { // size=1600*8=12800&lt;32768 if size &lt; _MaxSmallSize { // 12800&lt;=0 if size &lt;= smallSizeMax-8 { return uintptr(class_to_size[size_to_class8[(size+smallSizeDiv-1)/smallSizeDiv]]) } else { return uintptr(class_to_size[size_to_class128[(size-smallSizeMax+largeSizeDiv-1)/largeSizeDiv]])//size_to_class128[92]= 56 //class_to_size[56]=13568 //13568/8=1696 } } if size+_PageSize &lt; size { return size } return round(size, _PageSize) } const _MaxSmallSize = 32768 const smallSizeDiv = 8 const smallSizeMax = 1024 const largeSizeDiv = 128 总结 slice容量的扩容规则：当原slice的cap小于1024时，新slice的cap变为原来的2倍；原slice的cap大于1024时，新slice变为原来的1.25倍，按照这个规则扩充后，还会进行内存对齐操作。
回到开头，为什么确定切片容量的程序效率更高？因为他省去了扩容的步骤。
扩展：内存对齐的目的 假设CPU的内存读写单位为4字节
在内存对齐和非对齐情况下，读取变量a都仅需要读取一次。
在内存对齐情况下，如果要读取变量b，则仅需要读取1次，即第二部分（4-7）；而非对齐情况下，则需要读取2次，即第一部分（0-3）取后3个字节，第二部分取前1个字节，然后用或操作拼接成变量b。
因此，内存对齐在某些情况下可以减少内存的读取次数，提高性能，是一种空间换时间的策略。
  ]]></content></entry><entry><title>go test 的内联问题</title><url>/post/inlining/</url><categories><category>实战问题</category></categories><tags><tag>golang</tag><tag>test</tag></tags><content type="html"><![CDATA[   使用monkey对函数进行打桩单测的时候，发现打桩函数没有生效。
习惯直接使用IDE的可视化的run和debug功能进行跑单测，没有关注到具体执行的命令。
单测代码 func TestLogin(t *testing.T) { // 初始化 dao 层 userDao := &amp;daoUser.UserDao{} // 初始化 service 层 entity := &amp;LoginService{} Convey(&#34;GetUserByUsername&#34;, t, func() { Convey(&#34;Should be success&#34;, func() { // 给 GetByUsername 函数打桩，指定返回值 patches := ApplyMethod(reflect.TypeOf(UserDao), &#34;GetByUsername&#34;, func(*daoUser.UserDao, string) (*daoUser.User, error) { return &amp;daoUser.User{ ID: 1, Username: &#34;weirwei&#34;, Password: &#34;123456&#34;, }, nil }) defer patches.Reset() // 测试 Login res, err := entity.Login(&#34;weirwei&#34;, &#34;123456&#34;) // 断言 So(err, ShouldBeNil) So(res, ShouldBeTrue) }) }) } 问题分析 查看run和debug的命令
# run /usr/local/go/bin/go test -c -o /private/var/folders/1q/llslx_n95d1brs7hq2drxjjw0000gn/T/___1go_test_gin_study_service_svUser gin-study/service/svUser # debug /usr/local/go/bin/go test -c -o /private/var/folders/1q/llslx_n95d1brs7hq2drxjjw0000gn/T/___go_test_gin_study_service_svUser -gcflags all=-N -l gin-study/service/svUser 很明显就能发现debug比run多了 -gcflags all=-N -l，这个就是==禁用内联==的选项
内联(inlining)：粗暴的来说，就是将函数内容复制到函数调用的地方，==减少了函数调用的开支==，但一定程度上会增加程序的代码量，==占用更多的内存==。
这么看就很明显了，本来打桩后 GetUserByUsername 会直接返回给定的结果，不走 dao 层的实际代码，但是 go 在编译过程中会进行内联优化，将 dao 层的代码直接“复制”过来，绕过了测试桩。而在本段测试代码中并没有对 dao 层进行相关配置及初始化，导致代码在执行时出现错误。
  ]]></content></entry><entry><title>Typora + PicGo + Gitee 解放你对图片的管理</title><url>/post/typora+picgo+gitee/</url><categories><category>实用工具</category></categories><tags><tag>Markdown</tag><tag>图床</tag></tags><content type="html"> 使用markdown做笔记的时候，使用图片时，需要将图片放在指定文件夹，然后引用。这么做每次添加图片都比较困难，并且不便于多端使用。
使用PicGo作为图床，将图片托管到Gitee，在使用Typora做笔记的时候可以直接无缝上传图片。
计算机环境准备 Typora PicGo nodejs Typora官网: https://typora.io/ PicGo官网: https://picgo.github.io/PicGo-Doc/zh/guide/ nodejs下载地址: http://nodejs.cn/download/ 设置 Gitee 作为 PicGo 的默认图床 在 PicGo 安装 gitee 插件 在插件设置搜索gitee，选择其中一个安装(两个都可以，只是配置内容有稍许不同)
在 Gitee 创建图片仓库 注意==仓库必须公开并且使用Readme初始化==
进行图床配置 若在图床设置中未找到 Gitee 图床，重启 PicGo 即可
owner: Gitee 用户名 repo: Gitee 仓库名 path: Gitee 存放图片的文件夹路径 token: Gitee 私人令牌 message: commit 信息 生成私人令牌: 设置-&amp;gt; 私人令牌 -&amp;gt; 生成新令牌
只勾选 projects 即可
提交后复制 token 至 PicGo 即可
可在上传区进行测试
配置 Typora 上传服务 然后开始愉快地 Markdown 吧！</content></entry><entry><title>关于 Hugo NexT 组织</title><url>/about.html</url><categories/><tags/><content type="html"> Hugo NexT 组织是由众多喜爱 NexT 主题及风格的世界各地友人共同组建而成，为的就是让这个主题继续在 Hugo 引擎中也能得到发扬光大，在此也欢迎你的加入！
我们的愿景 延续 NexT 经典的黑白调搭配，保持简单的易用性及强大的功能。
使用反馈 加入 GitHub Discussions 或 Gitter 在线讨论 🍻 GitHub Issues 提交错误报告 🐛 GitHub Feature 表新功能的想法 ✨ 同时国内用户也可加入 QQ 群交流： 604710815</content></entry><entry><title>站点示例</title><url>/flinks.html</url><categories/><tags/><content type="html"> 如想交换本站友情链接，请在评论区留下你的站点信息，格式参考如下：
- name: Hugo-NexT desc: Hugo NexT 官方预览网站。 avatar: https://hugo-next.eu.org/imgs/hugo_next_avatar.png link: https://hugo-next.eu.org</content></entry></search>