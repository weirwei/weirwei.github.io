<?xml version="1.0" encoding="utf-8" standalone="yes"?><search><entry><title>【leetcode】215. 数组中的第K个最大元素</title><url>/post/leetcode/leetcode_kth-largest-element-in-an-array/</url><categories><category>leetcode</category></categories><tags><tag>桶排序</tag></tags><content type="html"><![CDATA[   https://leetcode.cn/problems/kth-largest-element-in-an-array/ 给定整数数组 nums 和整数 k，请返回数组中第 k 个最大的元素。
请注意，你需要找的是数组排序后的第 k 个最大的元素，而不是第 k 个不同的元素。
你必须设计并实现时间复杂度为 O(n) 的算法解决此问题。
示例 1:
输入: [3,2,1,5,6,4], k = 2 输出: 5 示例 2: 输入: [3,2,3,1,2,4,5,5,6], k = 4 输出: 4 提示：
1 &lt;= k &lt;= nums.length &lt;= 10^5
-10^4 &lt;= nums[i] &lt;= 10^4
解题思路 先考虑一下隐藏条件： 元素可能会重复 首先想到的，因为 nums 是无序的，因此至少需要遍历一遍，题目要求 O(n) ，则表示需要在遍历的过程中排好序。自然就想到了桶排序。 代码 func findKthLargest(nums []int, k int) int { bucket := make([]int, 20001) for _, v := range nums { bucket[v+10000]++ } count := len(bucket) - 1 for { if bucket[count] &gt; 0 { k = k - bucket[count] } if k &lt;= 0 { return count - 10000 } count-- } } 后记 看一眼答案，居然是快排 T_T 。个人其实不喜欢用桶排序，因为受下标约束，不够泛用，并且它的思想很别扭，感觉就像使用redis的时候kv反着存。
但是既然已经写了，并且漂亮地通过了，那么快排兄，下次一定！溜~
  ]]></content></entry><entry><title>go 结构体包含接口成员进行反序列化</title><url>/post/go_struct_contains_interface/</url><categories><category>实战问题</category></categories><tags><tag>golang</tag><tag>json</tag></tags><content type="html"><![CDATA[   工作中遇到一个问题，结构体包含接口类型的成员时，在反序列化的时候会报错。
// Task 接口类型 type Task interface { Exec() error } // TaskA Task接口的实现类A type TaskA struct { A string `json:&#34;a&#34;` } func (ta *TaskA) Exec() error { fmt.Println(&#34;TaskA Exec&#34;) return nil } // TaskB Task接口的实现类B type TaskB struct { B string `json:&#34;b&#34;` } func (tb *TaskB) Exec() error { fmt.Println(&#34;TaskB Exec&#34;) return nil } // MixedStruct 反序列化目标结构体 type MixedStruct struct { Id uint64 `json:&#34;id&#34;` Task Task `json:&#34;task&#34;` } 场景 这个结构体在反序列化的过程中会报错。
需要给接口赋值具体的结构体才能正常反序列化。
func TestUnmarshal(t *testing.T) { t.Run(&#34;带 Interface 的结构体反序列化&#34;, func(t *testing.T) { str := &#34;{\&#34;id\&#34;:1,\&#34;task\&#34;:{\&#34;a\&#34;:\&#34;a\&#34;}}&#34; var mixed MixedStruct err := jsoniter.UnmarshalFromString(str, &amp;mixed) assert.NotNil(t, err) t.Log(err) // json_jsoniter.MixedStruct.Task: decode non empty interface: can not unmarshal into nil, error found in #10 byte of ...|:1,&#34;task&#34;:{&#34;a&#34;:&#34;a&#34;}}|..., bigger context ...|{&#34;id&#34;:1,&#34;task&#34;:{&#34;a&#34;:&#34;a&#34;}}|... mixed.Task = &amp;TaskA{} err = jsoniter.UnmarshalFromString(str, &amp;mixed) assert.Nil(t, err) }) } 解决方案 方案一 直接干掉问题，不存接口，存JSON字符串。
优点：简单粗暴
缺点：必须在业务中解析这个字段，加大了复杂度，增加了重复工作。
方案二 在业务中给接口成员赋值。
如：
mixed.Task = &amp;TaskA{} _ = jsoniter.UnmarshalFromString(str, &amp;mixed) 优点：简单粗暴
缺点：赋值成为前置条件，不同于正常的反序列化操作，在实际工程中容易遗忘。且在协同开发时必须和所有开发成员同步。
方案三 增加一个 taskType 类型，来表示实现哪个结构体
实现 UnmarshalJSON 函数
const ( TaskTypeA = 1 TaskTypeB = 2 ) type MixedStruct struct { Id uint64 `json:&#34;id&#34;` TaskType int `json:&#34;taskType&#34;` Task Task `json:&#34;task&#34;` } func (a *MixedStruct) UnmarshalJSON(b []byte) error { if a.Task == nil { // 给接口赋值具体实现类 taskType := jsoniter.Get(b, &#34;taskType&#34;) switch taskType.ToInt() { case TaskTypeA: a.Task = &amp;TaskA{} case TaskTypeB: a.Task = &amp;TaskB{} default: return errors.New(&#34;illegal task type&#34;) } } // 结构需要跟MixedStruct 保持一致 tmp := struct { Id uint64 `json:&#34;id&#34;` TaskType int `json:&#34;taskType&#34;` Task Task `json:&#34;task&#34;` }{} tmp.Task = a.Task if err := jsoniter.Unmarshal(b, &amp;tmp); err != nil { return err } a.Id = tmp.Id a.Task = tmp.Task a.TaskType = tmp.TaskType return nil } 优点：完美解决问题，反序列化的时候不需要额外操作
缺点：有维护成本，需要维护taskType的枚举值，且在给MixedStruct 增加字段的时候必须对应维护UnmarshalJSON的实现。
主要是想介绍这个方案三，对于它的缺点：
taskType 这个值基本上不论是否用接口成员，都需要维护，没有增加实际成本。 可以把 MixedStruct 和 UnmarshalJSON 放在一个文件里，并在接口成员的后面加上对应注释，起到备忘和提示的作用。 还有一点需要注意，在赋值 Task 的时候，不要用使用类似于 a.Task = b.Task ，因为 Task 是地址类型，使用的是同一片内存，修改 a.Task 的时候，b.Task 也会受影响，建议给Task 增加一个 Copy() 方法，实现深拷贝。
  ]]></content></entry><entry><title>【leetcode】146. LRU 缓存</title><url>/post/leetcode/leetcode_lru-cache/</url><categories><category>leetcode</category></categories><tags><tag>链表</tag><tag>缓存</tag></tags><content type="html"><![CDATA[   https://leetcode.cn/problems/lru-cache 请你设计并实现一个满足 LRU (最近最少使用) 缓存 约束的数据结构。
实现 LRUCache 类：
LRUCache(int capacity) 以 正整数 作为容量 capacity 初始化 LRU 缓存 int get(int key) 如果关键字 key 存在于缓存中，则返回关键字的值，否则返回 -1 。 void put(int key, int value) 如果关键字 key 已经存在，则变更其数据值 value ；如果不存在，则向缓存中插入该组 key-value 。如果插入操作导致关键字数量超过 capacity ，则应该 逐出 最久未使用的关键字。 函数 get 和 put 必须以 O(1) 的平均时间复杂度运行。 示例：
输入 [&#34;LRUCache&#34;, &#34;put&#34;, &#34;put&#34;, &#34;get&#34;, &#34;put&#34;, &#34;get&#34;, &#34;put&#34;, &#34;get&#34;, &#34;get&#34;, &#34;get&#34;] [[2], [1, 1], [2, 2], [1], [3, 3], [2], [4, 4], [1], [3], [4]] 输出 [null, null, null, 1, null, -1, null, -1, 3, 4] 解释 LRUCache lRUCache = new LRUCache(2); lRUCache.put(1, 1); // 缓存是 {1=1} lRUCache.put(2, 2); // 缓存是 {1=1, 2=2} lRUCache.get(1); // 返回 1 lRUCache.put(3, 3); // 该操作会使得关键字 2 作废，缓存是 {1=1, 3=3} lRUCache.get(2); // 返回 -1 (未找到) lRUCache.put(4, 4); // 该操作会使得关键字 1 作废，缓存是 {4=4, 3=3} lRUCache.get(1); // 返回 -1 (未找到) lRUCache.get(3); // 返回 3 lRUCache.get(4); // 返回 4 提示：
1 &lt;= capacity &lt;= 3000 0 &lt;= key &lt;= 10000 0 &lt;= value &lt;= 105 最多调用 2 * 105 次 get 和 put
解题思路 实现功能 主要功能是 Get 和 Put，先分析一下这两个方法需要实现什么功能
Get
获取缓存值 提高key的优先级 Put
key 已存在 设置缓存 设置当前key 的优先级为最高 key 不存在 设置缓存 设置当前key 的优先级为最高 检查缓存容量 数据结构 首先是缓存内容，便于存取，使用map 最合适
其次是优先级，他需要需要支持
将某个key的优先级提到最高 删除优先级最低的key 这里就考虑到了 切片、链表
切片：删除key 比较方便。但是定位key来提升优先级需要 O(n) 的复杂度 链表：删除key 需要知道表尾，用双向链表。提升优先级将对应的节点提到表头即可。双向链表完成这两个能力的成本更低。 代码 type Node struct { key, val int pre, next *Node } type LRUCache struct { m map[int]*Node // 缓存映射 head, tail *Node // 双向链表，维护优先级，head 指向优先级最高 cap int // 最大容量 size int // 当前缓存数量 } func Constructor(capacity int) LRUCache { l := LRUCache{ m: make(map[int]*Node, capacity), head: &amp;Node{}, tail: &amp;Node{}, cap: capacity, } l.head.next = l.tail l.tail.pre = l.head return l } /* * Get 获取缓存 1. 获取缓存值 2. 提高当前key 的优先级 */ func (this *LRUCache) Get(key int) int { node, ok := this.m[key] if ok { this.moveToHead(node) return node.val } return -1 } /* * Put 设置缓存 两种情况： case1：key 已存在 1. 设置缓存 2. 提高当前key 的优先级 case2: key 不存在 1. 设置缓存 2. 在表头插入key 3. 检查缓存容量 */ func (this *LRUCache) Put(key int, value int) { node, ok := this.m[key] if ok { node.val = value this.moveToHead(node) } else { node = &amp;Node{ key: key, val: value, } this.m[key] = node this.addToHead(node) this.size++ } for this.size &gt; this.cap { tail := this.removeTail() delete(this.m, tail.key) this.size-- } } func (this *LRUCache) addToHead(node *Node) { node.pre = this.head node.next = this.head.next this.head.next.pre = node this.head.next = node } func (this *LRUCache) removeNode(node *Node) { node.pre.next = node.next node.next.pre = node.pre } func (this *LRUCache) moveToHead(node *Node) { this.removeNode(node) this.addToHead(node) } func (this *LRUCache) removeTail() *Node { node := this.tail.pre this.removeNode(node) return node }   ]]></content></entry><entry><title>【leetcode】206. 反转链表</title><url>/post/leetcode/leetcode_reverse-linked-list/</url><categories><category>leetcode</category></categories><tags><tag>链表</tag><tag>滑动窗口</tag></tags><content type="html"> https://leetcode.cn/problems/reverse-linked-list 给你单链表的头节点 head ，请你反转链表，并返回反转后的链表。
示例 1：
输入：head = [1,2,3,4,5] 输出：[5,4,3,2,1] 示例 2：
输入：head = [1,2] 输出：[2,1] 示例 3：
输入：head = [] 输出：[] 提示：
链表中节点的数目范围是 [0, 5000] -5000 &amp;lt;= Node.val &amp;lt;= 5000
进阶：链表可以选用迭代或递归方式完成反转。你能否用两种方法解决这道题？
解题思路 方案一
遍历入堆栈，再读一遍 方案二
直接调转指向，用临时节点记录中间值 方案三
递归回溯 这个方案没想到，利用递归从链表尾回溯到链表头，完成翻转 本着做题的目的，我的coding是方案二。其实实际开发中遇到类似的问题，性能内存不是瓶颈的情况下，我会毫不犹豫地选择方案一。可读性高，而且不容易出错。
代码 func reverseList(head *ListNode) *ListNode { if head == nil || head.Next == nil { return head } var target, mid1, mid2 *ListNode mid1, mid2 = head, head.Next for mid2 != nil { mid2 = mid1.Next mid1.Next = target target = mid1 mid1 = mid2 } return target }</content></entry><entry><title>【leetcode】3. 无重复字符的最长子串</title><url>/post/leetcode/leetcode_longest-substring-without-repeating-characters/</url><categories><category>leetcode</category></categories><tags><tag>队列</tag><tag>滑动窗口</tag></tags><content type="html"><![CDATA[   https://leetcode.cn/problems/longest-substring-without-repeating-characters/ 给定一个字符串 s ，请你找出其中不含有重复字符的 最长子串 的长度。
示例 1:
输入: s = &#34;abcabcbb&#34; 输出: 3 解释: 因为无重复字符的最长子串是 &#34;abc&#34;，所以其长度为 3。 示例 2:
输入: s = &#34;bbbbb&#34; 输出: 1 解释: 因为无重复字符的最长子串是 &#34;b&#34;，所以其长度为 1。 示例 3:
输入: s = &#34;pwwkew&#34; 输出: 3 解释: 因为无重复字符的最长子串是 &#34;wke&#34;，所以其长度为 3。 请注意，你的答案必须是 子串 的长度，&#34;pwke&#34; 是一个子序列，不是子串。 提示：
0 &lt;= s.length &lt;= 5 * 104 s 由英文字母、数字、符号和空格组成 解题思路 本题求的是子序列，是连续的，因此可以利用滑动窗口的思想和队列的数据结构。 子序列需要满足不重复的规则，可以遍历字符串，遇到重复的字符丢弃前一个该字符及其以前的部分，每次滑动都记录长度。 代码 func lengthOfLongestSubstring(s string) int { var max int m := make(map[rune]struct{}) var queue []rune for _, v := range s { if _, ok := m[v]; ok { for len(queue) &gt; 0 &amp;&amp; queue[0] != v { delete(m, queue[0]) queue = queue[1:] } delete(m, queue[0]) queue = queue[1:] } m[v] = struct{}{} queue = append(queue, v) if len(queue) &gt; max { max = len(queue) } } return max }   ]]></content></entry><entry><title>MySQL where 范围查询和 order by 关键字无法同时命中索引</title><url>/post/index_in_orderby/</url><categories><category>实战问题</category></categories><tags><tag>MySQL</tag><tag>索引</tag></tags><content type="html"><![CDATA[   开发中，使用 in 和 order by 的时候，发现无法同时命中索引。
使用 IN 运算符来过滤行时，MySQL 会先使用索引来定位表中的行，并将这些行的所有数据读入内存中。随后，MySQL 会根据查询语句中的 ORDER BY 子句对这些数据进行排序。
简单场景构造 CREATE TABLE `c` ( `id` bigint unsigned NOT NULL AUTO_INCREMENT, `a` int NOT NULL DEFAULT &#39;0&#39;, `b` int NOT NULL DEFAULT &#39;0&#39;, `c` int NOT NULL DEFAULT &#39;0&#39;, PRIMARY KEY (`id`), KEY `abc` (`a`,`b`,`c`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci -- data insert into c(a, b, c) values (1, 1, 1), (1, 1, 2), (1, 1, 3), (1, 2, 1), (1, 2, 2), (1, 2, 3), (1, 2, 3), (2, 2, 2), (3, 3, 3); Explain SELECT 非范围查询 explain select * from c where a = 1 and b = 1 order by c; /* +----+-------------+-------+------------+------+---------------+------+---------+-------------+------+----------+-------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+-------+------------+------+---------------+------+---------+-------------+------+----------+-------------+ | 1 | SIMPLE | c | NULL | ref | abc | abc | 8 | const,const | 3 | 100.00 | Using index | +----+-------------+-------+------------+------+---------------+------+---------+-------------+------+----------+-------------+ */ 能够完美命中索引。
范围查询 explain select * from c where a = 1 and b &gt; 1 order by c; /* +----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+------------------------------------------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+------------------------------------------+ | 1 | SIMPLE | c | NULL | range | abc | abc | 8 | NULL | 4 | 100.00 | Using where; Using index; Using filesort | +----+-------------+-------+------------+-------+---------------+------+---------+------+------+----------+------------------------------------------+ */ 范围查询用到了filesort，表示 order by没有命中索引，abc 索引的作用相当于 ab。
索引分析 索引结构
a b c 1 1 1 2 3 2 1 2 3 3 2 2 2 3 3 3 select * from c where a = 1 and b = 1 order by c; 在非范围查询的时候，可以发现，经过where语句，c的范围是 1、2、3，b已确定，c 有序，order by 可以命中索引。
select * from c where a = 1 and b &gt; 1 order by c; 在范围查询的时候，经过where语句，c的范围是 1、2、3、1、2、3、3，b无法确定（可能为1或2），c 为无序，order by 无法命中索引。
  ]]></content></entry><entry><title>Gorm 的黑魔法</title><url>/post/gorm_black_magic/</url><categories><category>实战问题</category></categories><tags><tag>golang</tag><tag>gorm</tag></tags><content type="html"><![CDATA[   小伙看到同事写的Gorm黑魔法，逐渐不淡定了。
开发过程中，看到同事的代码写了这么一段：
db = db.Session(&amp;amp;gorm.Session{Context: db.Statement.Context}).FirstOrCreate(&amp;amp;entity) if db.Error !=nil{ return components.ErrorDbInsert.WrapPrintf(db.Error, &amp;#34;Insert error, entity:%s&amp;#34;, utils.ToJson(entity)) } if db.RowsAffected == 0 { return components.ErrorAlreadyExist } FirstOrCreate 我不禁感到疑惑，gorm 的 RowsAffected 在进行查询，如果查到数据，也是有值的，为什么在这里可以用 RowsAffected == 0 来判断数据已存在？
抱着这个疑问，我点开了 FirstOrCreate 的代码：
func (db *DB) FirstOrCreate(dest interface{}, conds ...interface{}) (tx *DB) { queryTx := db.Limit(1).Order(clause.OrderByColumn{ Column: clause.Column{Table: clause.CurrentTable, Name: clause.PrimaryKey}, }) if tx = queryTx.Find(dest, conds...); queryTx.RowsAffected == 0 { ... return tx.Create(dest) } else if len(db.Statement.assigns) &amp;gt; 0 { ... return tx.Model(dest).Updates(assigns) } return db } 我们可以很容易地发现，在 Find 查到数据且 assigns 没有值的情况下，return 的是 db，而其他情况下 return 的是 tx。直觉告诉我，原因大概率在这个上面。
getInstance() Limit、Order、Find等许多函数都调用了同一 …  ]]></content></entry><entry><title>MySQL 索引排序</title><url>/post/mysql_index_sort/</url><categories><category>存储</category></categories><tags><tag>MySQL</tag><tag>索引</tag></tags><content type="html"> 开发过程中发现SQL一直filesort，所以研究一下到低怎么才能使用索引进行排序。
表结构和数据 CREATE TABLE `t1` ( `id` int(11) NOT NULL AUTO_INCREMENT, `a` int(11) DEFAULT NULL, `b` int(11) DEFAULT NULL, `c` int(11) DEFAULT NULL, PRIMARY KEY (`id`), KEY `idx_a_b_c` (`a`,`b`,`c`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; id a b c 1 1 5 3 2 5 3 3 3 4 5 9 4 2 6 1 5 4 3 2 6 5 5 5 7 1 2 1 8 5 5 8 9 5 3 9 10 5 5 1 11 5 7 7 SQL explain select * from t where a = 5 order by c desc; -- type:ref -- key:idx_a_b_c -- ref:const -- Extra:Using where; Using index; Using filesort explain select * from t where a = 5 order by b desc; -- type:ref -- key:idx_a_b_c -- ref:const -- Extra:Using where; Using index explain select * from t where a = 5 and c = 5 order by b desc; -- type:ref -- key:idx_a_b_c -- ref:const -- Extra:Using where; Using index explain select * from t where a = 5 and b = 5 order by c desc; -- type:ref -- key:idx_a_b_c -- ref:const,const -- Extra:Using where; Using index explain select * from t where a = 5 and b &amp;gt;= 5 order by c desc; -- type:range -- key:idx_a_b_c -- ref:NULL -- Extra:Using where; Using index; Using filesort 索引分析 通过观察联合索引的数据结构，很明显就能发现索引都是有序的，使用索引进行排序就是利用了这个特性。
我们来观察 a = 5 的这一段索引，很容易就能发现，在 a 确定的情况下，b 是有序的，但c 是无序的。a 和 b 命中索引，a 和 c 不命中索引
在 a,b 都确定的情况下，c 是有序的。a,b,c 命中索引
这就是老生常谈的 最佳左前缀原则 也叫 最左前缀匹配原则
因此，要让排序项使用索引进行排序
第一个条件就是：where条件+排序项符合最佳左前缀原则
第二个条件：不能使用条件查询
这个也可以通过观察联合索引得出结论
a = 5 AND b &amp;gt;= 5 显然是无法保证 c 是有序的
结论 要让order by 使用索引排序，需要至少满足以下条件：
where条件+排序项符合最佳左前缀原则 不能使用条件查询</content></entry><entry><title>go 的切片扩容</title><url>/post/slice_expand/</url><categories><category>语言学习</category></categories><tags><tag>golang</tag></tags><content type="html"><![CDATA[   在uber 的go语言编码规范中有这么一条，2.48s 和0.21s 的差距还是很惊人了，我很好奇，why？
切片在append的时候可能会自动扩容，看一下相关源码。
slice type slice struct { array unsafe.Pointer len int cap int } func makeslice(et *_type, len, cap int) unsafe.Pointer { // 1. 计算需要申请的容量，并判断是否内存溢出 mem, overflow := math.MulUintptr(et.size, uintptr(cap)) // 2. 内存溢出原因 if overflow || mem &gt; maxAlloc || len &lt; 0 || len &gt; cap { // 计算slice所需内存通过MulUintptr来实现的 mem, overflow := math.MulUintptr(et.size, uintptr(len)) if overflow || mem &gt; maxAlloc || len &lt; 0 { panicmakeslicelen() } panicmakeslicecap() } // 3. 进行内存分配 return mallocgc(mem, et, true) } func growslice(et *_type, old slice, cap int) slice { ... newcap := old.cap doublecap := newcap + newcap if cap &gt; doublecap { newcap = cap } else { // 当原切片长度小于1024时，新切片的容量会直接翻倍。而当原切片的容量大于等于1024时，会反复地增加25%，直到新容量超过所需要的容量 if old.cap &lt; 1024 { newcap = doublecap } else { for 0 &lt; newcap &amp;&amp; newcap &lt; cap { newcap += newcap / 4 } if newcap &lt;= 0 { newcap = cap } } } var overflow bool var lenmem, newlenmem, capmem uintptr switch { case et.size == 1: lenmem = uintptr(old.len) newlenmem = uintptr(cap) capmem = roundupsize(uintptr(newcap)) overflow = uintptr(newcap) &gt; maxAlloc newcap = int(capmem) case et.size == sys.PtrSize: lenmem = uintptr(old.len) * sys.PtrSize newlenmem = uintptr(cap) * sys.PtrSize capmem = roundupsize(uintptr(newcap) * sys.PtrSize) overflow = uintptr(newcap) &gt; maxAlloc/sys.PtrSize newcap = int(capmem / sys.PtrSize) case isPowerOfTwo(et.size): var shift uintptr if sys.PtrSize == 8 { // Mask shift for better code generation. shift = uintptr(sys.Ctz64(uint64(et.size))) &amp; 63 } else { shift = uintptr(sys.Ctz32(uint32(et.size))) &amp; 31 } lenmem = uintptr(old.len) &lt;&lt; shift newlenmem = uintptr(cap) &lt;&lt; shift capmem = roundupsize(uintptr(newcap) &lt;&lt; shift) overflow = uintptr(newcap) &gt; (maxAlloc &gt;&gt; shift) newcap = int(capmem &gt;&gt; shift) default: lenmem = uintptr(old.len) * et.size newlenmem = uintptr(cap) * et.size capmem, overflow = math.MulUintptr(et.size, uintptr(newcap)) capmem = roundupsize(capmem) newcap = int(capmem / et.size) } ... } package runtime // 内存对齐的过程，为了避免造成过多的内存碎片 func roundupsize(size uintptr) uintptr { // size=1600*8=12800&lt;32768 if size &lt; _MaxSmallSize { // 12800&lt;=0 if size &lt;= smallSizeMax-8 { return uintptr(class_to_size[size_to_class8[(size+smallSizeDiv-1)/smallSizeDiv]]) } else { return uintptr(class_to_size[size_to_class128[(size-smallSizeMax+largeSizeDiv-1)/largeSizeDiv]])//size_to_class128[92]= 56 //class_to_size[56]=13568 //13568/8=1696 } } if size+_PageSize &lt; size { return size } return round(size, _PageSize) } const _MaxSmallSize = 32768 const smallSizeDiv = 8 const smallSizeMax = 1024 const largeSizeDiv = 128 总结 slice容量的扩容规则：当原slice的cap小于1024时，新slice的cap变为原来的2倍；原slice的cap大于1024时，新slice变为原来的1.25倍，按照这个规则扩充后，还会进行内存对齐操作。
回到开头，为什么确定切片容量的程序效率更高？因为他省去了扩容的步骤。
扩展：内存对齐的目的 假设CPU的内存读写单位为4字节
在内存对齐和非对齐情况下，读取变量a都仅需要读取一次。
在内存对齐情况下，如果要读取变量b，则仅需要读取1次，即第二部分（4-7）；而非对齐情况下，则需要读取2次，即第一部分（0-3）取后3个字节，第二部分取前1个字节，然后用或操作拼接成变量b。
因此，内存对齐在某些情况下可以减少内存的读取次数，提高性能，是一种空间换时间的策略。
  ]]></content></entry><entry><title>go test 的内联问题</title><url>/post/inlining/</url><categories><category>实战问题</category></categories><tags><tag>golang</tag><tag>test</tag></tags><content type="html"><![CDATA[   使用monkey对函数进行打桩单测的时候，发现打桩函数没有生效。
习惯直接使用IDE的可视化的run和debug功能进行跑单测，没有关注到具体执行的命令。
单测代码 func TestLogin(t *testing.T) { // 初始化 dao 层 userDao := &amp;daoUser.UserDao{} // 初始化 service 层 entity := &amp;LoginService{} Convey(&#34;GetUserByUsername&#34;, t, func() { Convey(&#34;Should be success&#34;, func() { // 给 GetByUsername 函数打桩，指定返回值 patches := ApplyMethod(reflect.TypeOf(UserDao), &#34;GetByUsername&#34;, func(*daoUser.UserDao, string) (*daoUser.User, error) { return &amp;daoUser.User{ ID: 1, Username: &#34;weirwei&#34;, Password: &#34;123456&#34;, }, nil }) defer patches.Reset() // 测试 Login res, err := entity.Login(&#34;weirwei&#34;, &#34;123456&#34;) // 断言 So(err, ShouldBeNil) So(res, ShouldBeTrue) }) }) } 问题分析 查看run和debug的命令
# run /usr/local/go/bin/go test -c -o /private/var/folders/1q/llslx_n95d1brs7hq2drxjjw0000gn/T/___1go_test_gin_study_service_svUser gin-study/service/svUser # debug /usr/local/go/bin/go test -c -o /private/var/folders/1q/llslx_n95d1brs7hq2drxjjw0000gn/T/___go_test_gin_study_service_svUser -gcflags all=-N -l gin-study/service/svUser 很明显就能发现debug比run多了 -gcflags all=-N -l，这个就是==禁用内联==的选项
内联(inlining)：粗暴的来说，就是将函数内容复制到函数调用的地方，==减少了函数调用的开支==，但一定程度上会增加程序的代码量，==占用更多的内存==。
这么看就很明显了，本来打桩后 GetUserByUsername 会直接返回给定的结果，不走 dao 层的实际代码，但是 go 在编译过程中会进行内联优化，将 dao 层的代码直接“复制”过来，绕过了测试桩。而在本段测试代码中并没有对 dao 层进行相关配置及初始化，导致代码在执行时出现错误。
  ]]></content></entry><entry><title>Typora + PicGo + Gitee 解放你对图片的管理</title><url>/post/typora+picgo+gitee/</url><categories><category>实用工具</category></categories><tags><tag>Markdown</tag><tag>图床</tag></tags><content type="html"> 使用markdown做笔记的时候，使用图片时，需要将图片放在指定文件夹，然后引用。这么做每次添加图片都比较困难，并且不便于多端使用。
使用PicGo作为图床，将图片托管到Gitee，在使用Typora做笔记的时候可以直接无缝上传图片。
计算机环境准备 Typora PicGo nodejs Typora官网: https://typora.io/ PicGo官网: https://picgo.github.io/PicGo-Doc/zh/guide/ nodejs下载地址: http://nodejs.cn/download/ 设置 Gitee 作为 PicGo 的默认图床 在 PicGo 安装 gitee 插件 在插件设置搜索gitee，选择其中一个安装(两个都可以，只是配置内容有稍许不同)
在 Gitee 创建图片仓库 注意==仓库必须公开并且使用Readme初始化==
进行图床配置 若在图床设置中未找到 Gitee 图床，重启 PicGo 即可
owner: Gitee 用户名 repo: Gitee 仓库名 path: Gitee 存放图片的文件夹路径 token: Gitee 私人令牌 message: commit 信息 生成私人令牌: 设置-&amp;gt; 私人令牌 -&amp;gt; 生成新令牌
只勾选 projects 即可
提交后复制 token 至 PicGo 即可
可在上传区进行测试
配置 Typora 上传服务 然后开始愉快地 Markdown 吧！</content></entry><entry><title>关于 Hugo NexT 组织</title><url>/about.html</url><categories/><tags/><content type="html"> Hugo NexT 组织是由众多喜爱 NexT 主题及风格的世界各地友人共同组建而成，为的就是让这个主题继续在 Hugo 引擎中也能得到发扬光大，在此也欢迎你的加入！
我们的愿景 延续 NexT 经典的黑白调搭配，保持简单的易用性及强大的功能。
使用反馈 加入 GitHub Discussions 或 Gitter 在线讨论 🍻 GitHub Issues 提交错误报告 🐛 GitHub Feature 表新功能的想法 ✨ 同时国内用户也可加入 QQ 群交流： 604710815</content></entry><entry><title>站点示例</title><url>/flinks.html</url><categories/><tags/><content type="html"> 如想交换本站友情链接，请在评论区留下你的站点信息，格式参考如下：
- name: Hugo-NexT desc: Hugo NexT 官方预览网站。 avatar: https://hugo-next.eu.org/imgs/hugo_next_avatar.png link: https://hugo-next.eu.org</content></entry></search>